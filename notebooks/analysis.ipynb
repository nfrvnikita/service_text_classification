{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertModel\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import TFRobertaModel\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# our functions\n",
    "from src.data.make_dataset import final_dataset\n",
    "from src.data.fix_balance import sampling_balance\n",
    "from src.data.split_data import split\n",
    "from src.data.encode_data import ohe_encoding\n",
    "from src.data.vectorizer import text_vectorize\n",
    "\n",
    "#set seed for reproducibility\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>published</th>\n",
       "      <th>full review url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>«Головоломка» — продукт универсальный, и, чтоб...</td>\n",
       "      <td>90</td>\n",
       "      <td>2015-6-22</td>\n",
       "      <td>http://www.kino-mir.ru/posts/view/147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>А если подвести итоги, то Пиксар создал, не по...</td>\n",
       "      <td>100</td>\n",
       "      <td>2015-6-18</td>\n",
       "      <td>https://www.uralweb.ru/poster/reviews/6694.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>И все же плюсы «Головоломки» перевешивают ее м...</td>\n",
       "      <td>100</td>\n",
       "      <td>2015-6-19</td>\n",
       "      <td>http://www.tramvision.ru/recensia/2015/golovol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>На выходе из зала есть ощущение, что Pixar сде...</td>\n",
       "      <td>100</td>\n",
       "      <td>2015-6-18</td>\n",
       "      <td>http://afisha.ngs.ru/news/more/2181412/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Да, перед нами настоящий, старой школы пиксаро...</td>\n",
       "      <td>100</td>\n",
       "      <td>2015-6-16</td>\n",
       "      <td>http://www.kinokadr.ru/articles/2015/06/17/ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  published  \\\n",
       "0  «Головоломка» — продукт универсальный, и, чтоб...      90  2015-6-22   \n",
       "1  А если подвести итоги, то Пиксар создал, не по...     100  2015-6-18   \n",
       "2  И все же плюсы «Головоломки» перевешивают ее м...     100  2015-6-19   \n",
       "3  На выходе из зала есть ощущение, что Pixar сде...     100  2015-6-18   \n",
       "4  Да, перед нами настоящий, старой школы пиксаро...     100  2015-6-16   \n",
       "\n",
       "                                     full review url  \n",
       "0              http://www.kino-mir.ru/posts/view/147  \n",
       "1    https://www.uralweb.ru/poster/reviews/6694.html  \n",
       "2  http://www.tramvision.ru/recensia/2015/golovol...  \n",
       "3            http://afisha.ngs.ru/news/more/2181412/  \n",
       "4  http://www.kinokadr.ru/articles/2015/06/17/ins...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/nfrvnikita/projects/service4classification/data/raw/BRFRD.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генерация обработанного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfrvnikita/projects/service4classification/notebooks/../src/features/build_features.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['token_lens'] = token_lens\n"
     ]
    }
   ],
   "source": [
    "final_data = final_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "2    15526\n",
       "1     9706\n",
       "0     2063\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_os = sampling_balance(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "2    15526\n",
       "1    15526\n",
       "0    15526\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_os['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сплит данных на трейн и валид датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = split(data_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = ohe_encoding(y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Векторизация (TF-IDF, CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf, X_valid_tf = text_vectorize(X_train, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27295\n",
      "27295\n"
     ]
    }
   ],
   "source": [
    "print(len(final_data['class']))\n",
    "print(len(final_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = list(final_data['class'].unique())\n",
    "labels = dict(zip(CLASSES, range(len(CLASSES))))\n",
    "labels = [labels[label] for label in final_data['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_dataset import BERTDataset\n",
    "from src.models.train_model import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/nfrvnikita/projects/service4classification/data/raw/BRFRD.csv')\n",
    "model_path = 'cointegrated/rubert-tiny'\n",
    "tokenizer_path = 'cointegrated/rubert-tiny'\n",
    "bert_tiny = BertClassifier(model_path, tokenizer_path, data, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfrvnikita/projects/service4classification/notebooks/../src/features/build_features.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['token_lens'] = token_lens\n",
      "/home/nfrvnikita/projects/service4classification/notebooks/../src/features/build_features.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['token_lens'] = token_lens\n",
      "/home/nfrvnikita/projects/service4classification/.venv/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bert_tiny.preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5801/5801 [01:40<00:00, 57.68it/s]\n",
      "100%|██████████| 1024/1024 [00:07<00:00, 144.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.217                 | Train Accuracy:  0.576                     | Val Loss:  0.210                         | Val Accuracy:  0.590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5801/5801 [01:30<00:00, 64.21it/s]\n",
      "100%|██████████| 1024/1024 [00:07<00:00, 145.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.195                 | Train Accuracy:  0.634                     | Val Loss:  0.206                         | Val Accuracy:  0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5801/5801 [01:30<00:00, 64.32it/s]\n",
      "100%|██████████| 1024/1024 [00:07<00:00, 144.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.173                 | Train Accuracy:  0.693                     | Val Loss:  0.213                         | Val Accuracy:  0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5801/5801 [01:30<00:00, 64.15it/s]\n",
      "100%|██████████| 1024/1024 [00:07<00:00, 144.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.157                 | Train Accuracy:  0.732                     | Val Loss:  0.220                         | Val Accuracy:  0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17001, 3635.786056533456)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tiny.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
